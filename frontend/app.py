import streamlit as st
import json
import os
from rapidfuzz import process
import speech_recognition as sr
from transformers import AutoTokenizer, AutoModelForQuestionAnswering, pipeline

model_name = "google/muril-base-cased"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForQuestionAnswering.from_pretrained(model_name)

qa_pipeline = pipeline("question-answering", model=model, tokenizer=tokenizer)

# Dynamically resolve path
file_path = os.path.join(os.path.dirname(__file__), "..", "data", "schemes.json")

try:
    with open(file_path, "r", encoding="utf-8") as f:
        faq_data = json.load(f)
except Exception as e:
    st.error(f"Failed to load FAQ data: {e}")
    faq_data = []

st.title("Beej : рдХрд┐рд╕рд╛рди рд╕рд▓рд╛рд╣рдХрд╛рд░")

st.markdown("""
    **рдкреВрдЫреЗрдВ:** рдХреЛрдИ рднреА рд╕рд╡рд╛рд▓ рдЬреИрд╕реЗ "рдкреАрдПрдо-рдХрд┐рд╕рд╛рди рдпреЛрдЬрдирд╛ рдХреНрдпрд╛ рд╣реИ?"  
    **рдЙрддреНрддрд░:** рд╣рдо рдЖрдкрдХреЛ рдпреЛрдЬрдирд╛рдУрдВ рдХреА рдЬрд╛рдирдХрд╛рд░реА рджреЗрдВрдЧреЗ!
""")

query = st.text_input("Ask a question about PM-KISAN or Soil Health Card")

import speech_recognition as sr

def transcribe_voice():
    r = sr.Recognizer()
    with sr.Microphone() as source:
        st.info(" Speak now...")
        audio = r.listen(source)
    try:
        query = r.recognize_google(audio, language="hi-IN")  # Hindi support
        st.success(f" You said: {query}")
        return query
    except sr.UnknownValueError:
        st.error("Sorry, I couldn't understand your voice.")
    except sr.RequestError:
        st.error("Could not connect to the speech recognition service.")
    return ""



# Using Indic BERT for more complex queries
def get_llm_answer(query, faq_data):
    questions = [item["question"] for item in faq_data]
    match, score, index = process.extractOne(query, questions)
    if score > 60:
        context = faq_data[index].get("context", "")
        if context:
            result = qa_pipeline(question=query, context=context)
            return result["answer"]
        else:
            return faq_data[index]["answer"]
    return "рдорд╛рдлрд╝ рдХреАрдЬрд┐рдП, рдореБрдЭреЗ рдЖрдкрдХреЗ рд╕рд╡рд╛рд▓ рдХрд╛ рдЙрддреНрддрд░ рдирд╣реАрдВ рдорд┐рд▓рд╛ред"

if query:
    answer = get_llm_answer(query, faq_data)
    st.success(f"ЁЯЧия╕П {answer}")